\documentclass[12pt,a4paper]{article}
\usepackage{cmap} % Makes the PDF copyable. See http://tex.stackexchange.com/a/64198/25761
\usepackage[T1]{fontenc}
\usepackage[brazil]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{textcomp} % \degree
\usepackage{gensymb} % \degree
\usepackage[usenames,svgnames,dvipsnames]{xcolor}
\usepackage{hyperref}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage[margin=2cm]{geometry}
\usepackage{systeme}
\usepackage{icomma} % vírgulas como pontuação vs ponto decimal
\hypersetup{
    colorlinks = true,
    allcolors = {blue}
}

\newcommand{\fixme}{{\color{red}(...)}}
\newcommand*\sen{\operatorname{sen}}

\newcommand*\R{\mathbb{R}}

\newcommand{\IconPc}{\includegraphics[width=1em]{computer.png}}
\newcommand{\IconCalc}{\includegraphics[width=1em]{calculator.png}}
\newcommand{\IconThink}{\includegraphics[width=1em]{pencil.png}}
\newcommand{\IconCheck}{\includegraphics[width=1em]{checkmark.png}}
\newcommand{\IconConcept}{\includegraphics[width=1em]{edit.png}}

\newlength{\SmileysLength}
\setlength{\SmileysLength}{\labelwidth}\addtolength{\SmileysLength}{\labelsep}

\newcommand{\calc}{\hspace*{-\SmileysLength}\makebox[0pt][r]{\IconCalc}%
   \hspace*{\SmileysLength}}
\newcommand{\software}{\hspace*{-\SmileysLength}\makebox[0pt][r]{\IconPc}%
   \hspace*{\SmileysLength}}
\newcommand{\teoria}{\hspace*{-\SmileysLength}\makebox[0pt][r]{\IconThink}%
   \hspace*{\SmileysLength}}
\newcommand{\conceito}{\hspace*{-\SmileysLength}\makebox[0pt][r]{\IconCheck}%
   \hspace*{\SmileysLength}}
\newcommand{\concept}{\hspace*{-\SmileysLength}\makebox[0pt][r]{\IconCheck}%
   \hspace*{\SmileysLength}}

\newcommand*\tipo{Lista de Exercícios - Sistemas de Equações}
%\newcommand*\turma{...}
\newcommand*\disciplina{ANN0001/CAN0001}
\newcommand*\eu{Helder G. G. de Lima}
\newcommand*\data{\today}

\author{\eu}
\title{\tipo}
\date{\data}

\begin{document}

\begin{center}
\includegraphics[width=9.0cm]{marca} \\
\textbf{\tipo} \\
Prof. \eu\footnote{
Este é um material de acesso livre distribuído sob os termos da licença \href{https://creativecommons.org/licenses/by-sa/4.0/deed.pt_BR}{Creative Commons BY-SA 4.0}.}
\end{center}

%\section*{Legenda}
%\begin{multicols}{4}
%\begin{itemize}
%\item[] \hspace*{\SmileysLength} \calc \hspace*{-\SmileysLength} Cálculos
%\item[] \hspace*{\SmileysLength} \conceito \hspace*{-\SmileysLength} Conceitos
%\item[] \hspace*{\SmileysLength} \teoria \hspace*{-\SmileysLength} Teoria
%\item[] \hspace*{\SmileysLength} \software \hspace*{-\SmileysLength} Software
%\end{itemize}
%\end{multicols}

\section*{Questões}

\begin{enumerate}
\item %\calc
Sejam $A =
\begin{bmatrix}
-1 &  3 &  8 \\
 2 & -4 & -7 \\
-3 &  1 & -7
\end{bmatrix}$, $b =
\begin{bmatrix}
 24 \\
-30 \\
 10
\end{bmatrix}$ e $b^\prime =
\begin{bmatrix}
 18 \\
-13 \\
-23
\end{bmatrix}$.
\begin{enumerate}
\item Decomponha $A = L \cdot U$, usando a eliminação de Gauss (sem pivotamento).
\item Resolva $Ax = b$ usando a decomposição obtida anteriormente.
\item Utilize a mesma decomposição para resolver $Ax = b^\prime$.
\end{enumerate}

\item %\calc
Utilize a fatoração $LU$ para encontrar uma matriz $X$, de ordem $3 \times 3$, tal que
\[
\begin{bmatrix}
 24 &  12 & -6\\
 16 &   6 &  0\\
-18 & -14 & 15
\end{bmatrix}
\cdot X
=
\begin{bmatrix}
0&12&-12\\
2&12&-8\\
6&2&8
\end{bmatrix}.
\]

\item Mostre que se $A =\begin{bmatrix}
0 & 1\\
2 & 3
\end{bmatrix}$ então não existem $L = \begin{bmatrix}
1 & 0\\
c & 1
\end{bmatrix}$ e $U = \begin{bmatrix}
a & b\\
0 & d
\end{bmatrix}$ tais que $A=LU$.

\item %\calc
Calcule $A^{-1}$ resolvendo o sistema $A X = I_{3 \times 3}$ por meio da fatoração $LU$, sendo
\[
A =
\begin{bmatrix}
1&-1&-1\\
4&-3&-2\\
1&-4&-8
\end{bmatrix}.
\]

\item %\calc
Resolva o sistema linear
\[
\systeme[xy]{
0.00100 x + 4.00    y = 4.00,
4.00    x + 0.00100 y = 4.00
}
\]
usando 3 algarismos significativos durante os cálculos:
\begin{enumerate}
\item Através da eliminação de Gauss sem pivotamento.
\item Através da eliminação de Gauss com pivotamento parcial. Compare com o resultado anterior e com a solução exata, $x = y = \frac{4000}{4001} \approx 0.99975006$.
\end{enumerate}
\item Considere o seguinte sistema linear:
\systeme{
  x_1 - 2x_2 -   x_3 = -1,
-2x_1 + 2x_2 +  6x_3 = -5,
-5x_1 + 5x_2 + 10x_3 = -7.5
}
\begin{enumerate}
\item Utilize a eliminação de Gauss, sem pivotamento, para resolver o sistema
\item Substitua seus resultados nas equações originais para verificar suas respostas.
\end{enumerate}

\item Considere o seguinte sistema linear:
\systeme{
 4x_1 - 2x_2 -  x_3 = 3,
 2x_1 +  x_2 -  x_3 = 6,
10x_1 + 9x_2 - 3x_3 = 36
}
\begin{enumerate}
\item Utilize a eliminação de Gauss com pivotamento parcial, para resolver o sistema.
\item Substitua seus resultados nas equações originais para verificar suas respostas.
\end{enumerate}
\item Resolva os sistemas lineares a seguir por eliminação de Gauss ou por fatoração LU. Compare suas respostas com a que é obtida em um software como o Matlab ou o Scilab.
\begin{multicols}{2}
\begin{enumerate}
\item \systeme{
x_1 + 4x_2 - x_3 + 3x_4 = 2,
-x_1 -3x_2 + 5x_3 -4x_4 = 6,
x_1 + 6x_2 + 8x_3 + 5x_4 = 11,
    - 3x_2 -12x_3 +4x_4 = -26
}

\item \systeme{
  x_1 +       3x_3        = -2,
 2x_1 + x_2 + 6x_3 + 3x_4 =  7,
-5x_1       -14x_3        =  8,
               x_3 +  x_4 =  5
}
\end{enumerate}
\end{multicols}
\item Considere o sistema linear
\[
\systeme{
 3x_1 - x_2       + x_4 = 1,
-3x_1 +7x_2       -3x_4 = 11,
            2 x_3 - x_4 = 6,
 6x_1 -2x_2      +10x_4 = 2
}
\]
\begin{enumerate}
\item Utilize a eliminação de Gauss, sem pivotamento, para calcular a solução exata do sistema.
\item Verifique se a matriz do sistema é estritamente diagonal dominante. Se não for, permute suas equações para que a matriz associada seja estritamente diagonal dominante.
\item Obtenha soluções aproximadas do sistema anterior, efetuando 2 etapas dos métodos de Jacobi e de Gauss-Seidel, usando $x^{(0)} = (0, 0, 0, 0)^\intercal$ como aproximação inicial. Calcule o erro absoluto (exato e estimado) e também o erro percentual (exato e estimado) a cada iteração.
\end{enumerate}

\item Considere o sistema linear cuja representação matricial é:
\[
\begin{bmatrix}
 3 & 2 & 0 \\
-2 & k & 3 \\
 k & 3 & 10
\end{bmatrix}
\cdot
\begin{bmatrix}
x_1 \\ x_2 \\ x_3
\end{bmatrix}
=
\begin{bmatrix}
3 \\ -5 \\ -4
\end{bmatrix}
\]
\begin{enumerate}
\item Para quais valores de $k \in \mathbb{Z}$ a matriz do sistema é estritamente diagonal dominante?
\item Considerando o menor $k \in \mathbb{Z}$, positivo, nas condições anteriores, e efetue 3 iterações do método de Gauss-Seidel para resolver o sistema linear correspondente, partindo da aproximação inicial  $x^{(0)} = (0, 0, 0)^\intercal$. Estime os erros absoluto e relativo a cada iteração.
\end{enumerate}
\item Considere os sistemas lineares
\[(1)
\systeme{
2a+b    =1,
a-3b+c  =2,
  b+4c-d=3,
   -c-2d=4
}
\quad\text{ e }\quad
(2)
\systeme{
2a +b    =1,
-a-4b+c  =1,
  b+5c+d=-1,
   -c-2d=4
}
\]
\begin{enumerate}
\item Mostre que os sistemas são equivalentes (têm a mesma solução), identificando as operações elementares que podem ser realizadas com as equações do primeiro sistema para obter as do segundo sistema.
\item Se for utilizado o método de Gauss-Seidel para obter a solução destes sistemas, partindo da aproximação inicial $X^{(0)}=(a^{(0)}, b^{(0)}, c^{(0)},d^{(0)})^\intercal = (1, 0, 0, -2)^\intercal$, em qual dos casos serão necessárias menos iterações para obter uma solução com erro relativo percentual de no máximo $1\%$?
\end{enumerate}

\item O método iterativo $x^{(k+1)} = C x^{(k)} + d$ é convergente se, e somente se, o maior autovalor em módulo da matriz de iteração $C$ (o seu ``raio espectral'') é menor do que 1. Lembre-se que os autovalores de $C$ são as raízes (reais ou complexas) do polinômio $p( \lambda ) = \det( \lambda I - C)$.
\begin{enumerate}
\item Calcule a matriz de iteração $C$ do método de Jacobi para o sistema linear
\[
\systeme{
5x_1 + 8x_2 =  3,
7x_1 + 4x_2 = -3
}
\]
\item Determine o maior autovalor em módulo da matriz $C$ calculada anteriormente. O que pode ser dito a respeito da convergência do método de Jacobi para este sistema?
\item Se forem permutadas as equações do sistema linear acima, qual será a nova matriz de iteração? Calcule o maior autovalor em módulo desta matriz, e repita a análise da convergência do método de Jacobi para o novo sistema.
\item Caso o método de Jacobi convirja, quando aplicado a algum dos sistemas anteriores, utilize-o para obter uma solução aproximada $x^{(k)} = \left(x_1^{(k)}, x_2^{(k)}\right)^\intercal$, considerando que $x^{(0)} = (0, 0)^\intercal$, e realizando tantas iterações quantas forem necessárias para que a estimativa $\varepsilon = || x^{(k)} - x^{(k-1)} ||$ do erro absoluto fique menor do que $0,02$. Considere $|| x || = \max\{|x_1|, |x_2|\}$.
\end{enumerate}
\item Compare o número de iterações necessárias para que os métodos de Jacobi e de Gauss-Seidel produzam uma solução aproximada do sistema linear a seguir, com uma estimativa do erro relativo percentual de até $5\%$:
\systeme{
6x_1 + 4x_2 = 1,
3x_1 + 4x_2 = 0.
}

\item Considere o sistema não linear
\[
\begin{cases}
3x - \ln(y + 1) &= 0,\\
x^3 + 9y &= 1
\end{cases}
\]
\begin{enumerate}
\item Reescreva o sistema na forma de um problema de ponto-fixo, isto é, como $(x,y) = \varphi(x,y)$, para alguma função $\varphi$.
\item Mostre que $\varphi$ possui pelo menos um ponto fixo no quadrado $Q = [0,1] \times [0,1]$.
\item Mostre que o método de iteração de ponto fixo gera uma sequência que converge para o ponto fixo de $\varphi$, qualquer que seja a aproximação inicial escolhida em $Q$.
\item Obtenha a solução do sistema com um erro relativo percentual de no máximo $1\%$, utilizando a aproximação inicial $X^{(0)} = (1, 1)$.
\end{enumerate}
\end{enumerate}


\newpage
\section*{Respostas}
\begin{enumerate}
\item
\begin{enumerate}
\item $A = L \cdot U =
\begin{bmatrix}
 1 &  0 & 0 \\
-2 &  1 & 0 \\
 3 & -4 & 1
\end{bmatrix}
\cdot
\begin{bmatrix}
-1 & 3 & 8 \\
 0 & 2 & 9 \\
 0 & 0 & 5
\end{bmatrix}
$.

\item
$ x = \begin{bmatrix}
-8 \\ 0 \\ 2
\end{bmatrix}$.
\item
$ x = \begin{bmatrix}
0 \\ -2 \\ 3
\end{bmatrix}$.
\end{enumerate}

\item $\begin{bmatrix}
 24 &  12 & -6\\
 16 &   6 &  0\\
-18 & -14 & 15
\end{bmatrix}
=L \cdot U =
\begin{bmatrix}
1&0&0\\
\frac{2}{3}&1&0\\
-\frac{3}{4}&\frac{5}{2}&1
\end{bmatrix}
\cdot
\begin{bmatrix}
24&12&-6\\
0&-2&4\\
0&0&\frac{1}{2}
\end{bmatrix}$
e
$X = \begin{bmatrix}
-1&0&1\\
3&2&-4\\
2&2&-2
\end{bmatrix}$.
\item Observe que
\[
L U
=
\begin{bmatrix}
1 & 0\\
c & 1
\end{bmatrix}
\cdot
\begin{bmatrix}
a & b\\
0 & d
\end{bmatrix}
=
\begin{bmatrix}
a & b\\
ac & bc + d
\end{bmatrix}.
\]
Então, para que $A=\begin{bmatrix}
0 & 1\\
2 & 3
\end{bmatrix} = LU$, seria preciso que
\[
\begin{cases}
   a &= 0,\\
   b &= 1,\\
   ac &= 2,\\
   bc + d &= 3,
\end{cases}
\]
o que é impossível, já que $a = 0$ implica $ac = 0 \neq 2$.

\item $A = L \cdot U =
\begin{bmatrix}
1&0&0\\4&1&0\\1&-3&1
\end{bmatrix}
\cdot
\begin{bmatrix}
1&-1&-1\\0&1&2\\0&0&-1
\end{bmatrix}$
e
$A^{-1} = \begin{bmatrix}
-16&4&1\\
-30&7&2\\
13&-3&-1
\end{bmatrix}$.

\item \begin{enumerate}
\item $x = 0,00$ e $y = 1,00$
\item $x = 1,00$ e $y = 1,00$. Sem pivotamento, há um erro relativo de $100\%$ no valor de $x$, e com o pivotamento, esse erro é praticamente nulo ($0,\!025\%$).
\end{enumerate}
\item $x_1 = 1$, $x_2 = 1,\!5$ e $x_3 = -1$.
\item $x_1 = 1,\!5$, $x_2 = 2$ e $x_3 = -1$.
\item \begin{enumerate}
\item $L \cdot U =
\begin{bmatrix}
 1 &  0 & 0 & 0 \\
-1 &  1 & 0 & 0 \\
 1 &  2 & 1 & 0 \\
 0 & -3 & 0 & 1
\end{bmatrix}
\cdot
\begin{bmatrix}
 1 & 4 & -1 &  3 \\
 0 & 1 &  4 & -1 \\
 0 & 0 &  1 &  4 \\
 0 & 0 &  0 &  1
\end{bmatrix}$ e $x_1 = 1$, $x_2 = 2$, $x_3 = 1$, $x_4 = -2$.
\item $L \cdot U =
\begin{bmatrix}
 1 &  0 & 0 & 0 \\
 2 &  1 & 0 & 0 \\
-5 &  0 & 1 & 0 \\
 0 &  0 & 1 & 1
\end{bmatrix}
\cdot
\begin{bmatrix}
 1 & 0 &  3 &  0 \\
 0 & 1 &  0 &  3 \\
 0 & 0 &  1 &  0 \\
 0 & 0 &  0 &  1
\end{bmatrix}$ e $x_1 = 4$, $x_2 = -10$, $x_3 = -2$, $x_4 = 7$.
\end{enumerate}
\item \begin{enumerate}
\item $ x = \begin{bmatrix}
x_1 \\ x_2 \\ x_3 \\ x_4
\end{bmatrix} = \begin{bmatrix}
1 \\ 2 \\ 3 \\ 0
\end{bmatrix}$.
\item A matriz do sistema é estritamente diagonal dominante.
\item Pelo método de Jacobi, obtém-se $x^{(2)} = (0,790, 1,800, 3,100, 0,314)^\intercal:
$
\medskip
\begin{center}
\begin{tabular}{crrrrr}
\hline
$\boldsymbol{k}$     & 0 & 1 & 2\\
\hline
$\boldsymbol{x_1^{(k)}}$ & 0,000 & 0,333 & 0,790 \\
$\boldsymbol{x_2^{(k)}}$ & 0,000 & 1,571 & 1,800 \\
$\boldsymbol{x_3^{(k)}}$ & 0,000 & 3,000 & 3,100 \\
$\boldsymbol{x_4^{(k)}}$ & 0,000 & 0,200 & 0,314 \\
\hline
$\varepsilon_{abs}$ (exato) & - & 0,667 & 0,314 \\
\hline
$\varepsilon_{per}$ (exato) & - & 22,2\% & 10,5\% \\
\hline
$\varepsilon_{abs}$ (aprox.) & - & 3,000 & 0,457 \\
\hline
$\varepsilon_{per}$ (aprox.) & - & 100,0\% & 14,7\% \\
\hline
\end{tabular}
\end{center}
\medskip

Pelo método de Gauss-Seidel, obtém-se $x^{(2)} = (0,790, 2,057, 3,172, 0,137)^\intercal:
$
\medskip
\begin{center}
\begin{tabular}{crrrrr}
\hline
$\boldsymbol{k}$     & 0 & 1 & 2\\
\hline
$\boldsymbol{x_1^{(k)}}$ & 0,000 & 0,333 & 0,790 \\
$\boldsymbol{x_2^{(k)}}$ & 0,000 & 1,714 & 2,057 \\
$\boldsymbol{x_3^{(k)}}$ & 0,000 & 3,000 & 3,172 \\
$\boldsymbol{x_4^{(k)}}$ & 0,000 & 0,343 & 0,137 \\
\hline
$\varepsilon_{abs}$ (exato) & - & 0,667 & 0,210 \\
\hline
$\varepsilon_{per}$ (exato) & - & 22,2\% & 7,0\% \\
\hline
$\varepsilon_{abs}$ (aprox.) & - & 3,000 & 0,457 \\
\hline
$\varepsilon_{per}$ (aprox.) & - & 100,0\% & 14,4\% \\
\hline
\end{tabular}
\end{center}

\end{enumerate}
\item \begin{enumerate}
\item $k = 6$ ou $k = -6$
\item Para $k = 6$, a solução exata é $X = (x_1, x_2, x_3)^\intercal = (1, 0, -1)^\intercal$. Pelo método de Gauss-Seidel, obtém-se $x^{(2)} = (1,333, 0,036, -1,211)^\intercal:
$
\medskip
\begin{center}
\begin{tabular}{crrrrr}
\hline
$\boldsymbol{k}$     & 0 & 1 & 2\\
\hline
$\boldsymbol{x_1^{(k)}}$ & 0,000 & 1,000 & 1,333 \\
$\boldsymbol{x_2^{(k)}}$ & 0,000 & -0,500 & 0,036 \\
$\boldsymbol{x_3^{(k)}}$ & 0,000 & -0,850 & -1,211 \\
\hline
$\varepsilon_{abs}$ (aprox.) & - & 1,000 & 0,536 \\
\hline
$\varepsilon_{rel}$ (aprox.) & - & 1,000 & 0,402 \\
\hline
\end{tabular}
\end{center}
\end{enumerate}


\item \begin{enumerate}
\item As únicas diferenças entre os dois sistemas estão na segunda e na terceira equações. Assim, basta observar que se, no primeiro sistema, a primeira equação for subtraída termo a termo da segunda equação, o resultado será a segunda equação do segundo sistema. Analogamente, se a penúltima equação for subtraída da última, o resultado será a terceira equação do segundo sistema. Estas operações elementares preservam a solução do sistema, então eles são equivalentes.
\item No primeiro caso, é preciso executar até a quinta iteração para que o erro relativo percentual não ultrapasse $1\%$, ficando igual a $0,5\%$. Já no segundo sistema, chega-se ao mesmo erro relativo percentual ainda na terceira iteração.
\end{enumerate}
\item \begin{enumerate}
\item $C =
\begin{bmatrix}
0 & -8/5 \\
-7/4 & 0
\end{bmatrix}$
\item $|\lambda| = \sqrt{14/5}\approx 1,\!67332$. Como $|\lambda| > 1$, o método de Jacobi não converge.
\item $C =
\begin{bmatrix}
0 & -4/7 \\
-5/8 & 0
\end{bmatrix}$, $|\lambda| = \sqrt{5/14}\approx 0,\!597614$. Como $|\lambda| < 1$, há convergência.
\item A solução exata é $(x_1, x_2)^\intercal = (-1, 1)^\intercal$, e pelo método de Jacobi, obtém-se $x^{(7)} = (-0,974, 0,972)^\intercal$:
\medskip
\begin{center}
\begin{tabular}{crrrrrrrr}
\hline
$\boldsymbol{k}$     & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 \\
\hline
$\boldsymbol{x_1^{(k)}}$ & 0,000 & -0,429 & -0,643 & -0,796 & -0,873 & -0,927 & -0,955 & -0,974 \\
$\boldsymbol{x_2^{(k)}}$ & 0,000 & 0,375 & 0,643 & 0,777 & 0,873 & 0,921 & 0,954 & 0,972 \\
\hline
$\varepsilon_{abs}$ (aprox.) & - & 0,429 & 0,268 & 0,153 & 0,096 & 0,054 & 0,033 & 0,019 \\
\hline
\end{tabular}
\end{center}
\end{enumerate}

\item Solução exata: $x_1 = 1/3$ e $x_2 = -1/4$.
\begin{enumerate}
\item Jacobi: $x^{(9)} = (0,323, -0,235)^\intercal$, com cerca de $3,1\%$ de erro
\item Gauss-Seidel: $x^{(5)} = (0,323, -0,242)^\intercal$, com cerca de $3,1\%$ de erro
\end{enumerate}


\item A solução é $(\overline{x},\overline{y}) = (0,0351187281,\ 0,1111062986)$. A aproximação $X^{(4)}$ estará dentro da margem de erro especificada.
\end{enumerate}
\end{document}
